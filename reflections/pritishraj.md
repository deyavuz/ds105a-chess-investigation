## Technical Contributions:

For this project, my primary focus was data visualization and website development. However, given the dynamic nature of our team, I was also significantly involved in data collection. I worked extensively on NB02-Data-Processing.ipynb, NB04-Data-Visualization.ipynb, and the database, ensuring smooth data handling, visualization, and retrieval processes. My contributions were geared towards creating a streamlined workflow from data collection to presentation, making our project accessible and insightful.

A major area of my work involved optimizing data retrieval and processing. By refining our approach to handling large datasets, I helped maximize efficiency. I played a key role in implementing structured database queries which made it easier to extract meaningful insights while maintaining scalability.

I also took the lead in designing the website, ensuring it effectively presented our findings in a user-friendly manner. The goal was to create an intuitive interface where users could explore our insights without needing to sift through raw code. This involved front-end development with HTML, CSS, and Bootstrap, along with seamless integration of our database and visualizations.

One of the challenges I faced was maintaining interactivity in our graphs. Initially, exporting them as static PNG images seemed like a straightforward solution, but it removed crucial interactive features such as zooming and dynamic filtering. To resolve this, I explored different methods for exporting graphs as HTML files while preserving interactivity. This process was a great learning experience as it deepened my understanding of various visualization libraries such as plotly and matplotlab and their compatibility with HTML.

Additionally, I worked on developing the function for comparative graphing of two data time series, making it easier to analyze multiple datasets side by side. I also created the data retrieval from our database to ensure smooth integration with our visualization tools. When making technical decisions, I focused on improving code efficiency by introducing new libraries, restructuring scripts, and reducing redundancy through external function files.

## Team Collaboration:

Our team maintained a high level of collaboration, with clear communication and shared responsibility. We were aligned in our decision-making, which allowed for uniterupted workflow. While each team member had specific roles, we had an environment of mutual support, ensuring that help was available whenever needed.

Since my primary contributions were more towards the later stages of the project, I initially took on a floater role, assisting different aspects wherever necessary. This approach allowed me to gain a well-rounded understanding of our work and contribute meaningfully to multiple facets, including data collection, processing, visualization, and presentation.

We prioritized regular feedback and open communication, ensuring everyone remained well-informed about progress, challenges, and solutions. Using collaboration tools like GitHub further streamlined our workflow, preventing conflicts and enhancing version control.

## Learning Journey:

One of my most valuable takeaways from this project was improving my ability to collaborate effectively using GitHub. Initially, we faced challenges with commit conflicts and formatting issues, particularly with Jupyter Notebook files (.ipynb) converting into raw JSON. These experiences potrayed the need to improve my understanding of GitHub branching, pushing, and pulling, which I better developed over the course of the project.

Another key learning experience was improving data-handling efficiency. Instead of retrieving entire JSON files and filtering data afterward, I learned to filter data on-call and save only the necessary portions directly into a CSV or database. This method, particularly for Chess.com and FIDE data, significantly reduced unnecessary excess files.

I also enjoyed revisiting web development and expanding my knowledge of HTML, CSS, and Bootstrap. Bootstrap proved to be an effective tool for creating a responsive and visually appealing website without excessive manual styling. Through this process, I enhanced my ability to structure web pages in a way that presents data clearly and engagingly.

Additionally, our statistical analysis highlighted the need for me to deepen my understanding of data analysis techniques. While I am confident in visualization, I recognized the importance of improving my ability to interpret and analyze data. Moving forward, I plan to refine my analytical skills to ensure that our visualizations are both well-presented and statistically robust.

Overall, this project was an invaluable learning experience that helped me grow both technically and collaboratively. It strengthened my ability to work within a team, solve technical challenges, and communicate data-driven insights effectively. There are multiple take aways on how I can do better in a future project, but for now I really enjoyed working on this project with my group!